抓取过程被简化为“放下，合拢手指，拿起”三步，**机械手始终手指向下**，整个抓取动作只用**三个量描述：手掌平面位置x，y以及手指朝向**。**算法要做的就是根据摄像头数据，给出一组这样的动作参数以实现抓取**。

基于深度摄像头的抓取，传统方法中**最可靠的方式是根据点云数据进行图像分割，物体识别以及物体的位姿估计，再根据物体几何结构选择合适的抓取位置**。这种方法**要求物体模型已知**，同时，在衡量抓取位置优劣时要考虑到感知系统的不确定性，而非简单滴计算是否形成force closure：

> ##### **抓取算法2.0**
>
> 1. 从图像中识别出物体种类，估计物体位姿。
> 2. 根据物体几何结构随便选N个抓取的位置。
> 3. 根据某个评价函数，为每个抓取位置打分。
> 4. 选择得分最高的而抓取位置执行

**传统方法的主要缺点是环节多，每一环都有不少参数要调整**，因此整个系统使用起来的人工复杂度比较高。这也催生了近年来比较火的基于深度学习进行抓取的方法，采用卷积神经网络来描述一个从图像直接到抓取位置的映射：

> **抓取算法3.0**
>
> 从图像直接获取抓取位置并执行

比如CMU RI的Gupta组，把抓取位置进一步简化为仅判断抓取的角度，并使用多达5万次机器人抓取实验来训练所需的神经网络[^2]。Google DeepMind 尝试从一堆物体中进行抓取，场景更复杂，因而也使用了更大的数据量（超过八十万次抓取，十几台机械臂花了两个多月才收集完数据）[^3]。**这种方法看上去直接，然而实际使用起来采数据所花的人力物力远超过传统方法**。

为了让仿真数据能用来训练神经网络，这篇文章有几个值得注意的地方：

1. 在仿真中认为**引入模型误差**，这样训练出来的结果起码能对付人工引入的噪声；
2. **定量衡量**一个抓取的**抗干扰能力**，以此作为依据在多个候选解中取最优；
3. **把抓取表述成一个规模合适的问题，不考虑复杂的抓取动作**。不考虑背景干扰或遮挡，最重要的是**不做端到端**，神经网络不需要直接输出抓取位置，而是仅需要做一个评价函数，对一个给定的抓取位置打一个分数。问题的复杂度降低后，仿真的失真带来的不利影响也随之变小。使用这样训练出来的神经网络，相比算法2.0我们仍可以省略掉步骤一，于是有了最终版算法：

> 抓取算法4.0
>
> 1. 在点云上随便选N个抓取的位置；
> 2. 根据训练好的CNN评价函数，为每个抓取位置打分；
> 3. 选择得分最高的抓取位置执行。

下面就详细介绍神经网络评价函数是如何得到的。

### 抓取动作的神经网络评价函数



